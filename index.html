<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="LoRD-HOI: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation">
  <meta name="keywords" content="VLM adaptation, Low-rank decomposition, Zero-shot detection, Human-object interaction detection">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LoRD-HOI: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">LoRD-HOI: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">ICCV 2025</span>
        </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://chelsielei.github.io/" target="_blank">Qinqian Lei</a><sup>1</sup>, </span>
            <span class="author-block">
              <a href="https://hawkrsrch.github.io/" target="_blank">Bo Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://tanrobby.github.io/index.html" target="_blank">Robby T. Tan</a><sup>1,3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National University of Singapore,</span>
            <span class="author-block"><sup>2</sup>University of Mississippi,</span>
            <span class="author-block"><sup>3</sup>ASUS Intelligent Cloud Services (AICS)</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ChelsieLei/Lord-hoi"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="content has-text-centered">
      <img src="./imgs/teaser.jpg" alt="LoRD-HOI boosts zero-shot HOI detection with low-rank VLM feature adaptation" style="width:60%; max-width:800px; margin-bottom: 30px;">
    </div>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Lord-HOI </span> boosts zero-shot HOI detection with low-rank VLM feature adaptation, achieving better action distinction and generalization ability.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
              Zero-shot human-object interaction (HOI) detection remains a challenging task, particularly in generalizing to unseen actions. 
              Existing methods address this challenge by tapping Vision-Language Models (VLMs) to access knowledge beyond the training data. 
              However, they either struggle to distinguish actions involving the same object or demonstrate limited generalization to unseen classes.
          </p>
          <p>
              In this paper, we introduce LoRD-HOI (Low-Rank Decomposed VLM Feature Adaptation for Zero-Shot HOI Detection), a novel approach that both enhances generalization to unseen classes and improves action distinction.
              In training, LoRD-HOI decomposes VLM text features for given HOI classes via low-rank factorization, producing class-shared basis features and adaptable weights. 
              These features and weights form a compact HOI representation that preserves shared information across classes, enhancing generalization to unseen classes. 
              Subsequently, we refine action distinction by adapting weights for each HOI class and introducing human-object tokens to enrich visual interaction representations.
              To further distinguish unseen actions, we guide the weight adaptation with LLM-derived action regularization.
          </p>
          <p>
              Experimental results show that our method sets a new state-of-the-art across zero-shot HOI settings on HICO-DET, achieving an unseen-class mAP of 27.91 in the unseen-verb setting. 
          </p>

        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Pipeline -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Pipeline</h2>
        <div class="content has-text-justified">
           <p>
           Overview of our proposed pipeline.
          </p>
           <div class="content has-text-centered">
        <img src="./imgs/pipeline.jpg" alt="Framework overview" style="width:100%; max-width:800px; margin-bottom: 30px;">
        </div>
          <p>
        In the language branch, VLM text HOI features are decomposed into HOI basis features $$\bm{\mathrm{B}}$$ and HOI weights $$\bm{\mathrm{W}}$$. Similarly, action features are decomposed into action basis features $$\bm{\mathrm{B}^a}$$ and action weights $$\bm{\mathrm{W}^a}$$, where $$\bm{\mathrm{B}^a}$$ is selected from $$\bm{\mathrm{B}}$$. 
        The weight adaptation updates $$\bm{\mathrm{W}}$$ with LLM-derived action regularization $$\bm{\mathrm{W}^a}$$, containing LLM-generated action information. The text fusion module combines action and object text features. 
		    In the vision branch, we adapt the VLM visual encoder with human-object tokens. Then we crop humans, objects, and HOI union regions from encoder output ("H, O, U" in the figure). The image fusion module then combines human and object features. 
        The prediction combines vision and language branches. 
          </p>

        </div>
      </div>
    </div>
    <!--/ Pipeline -->

  </div>
</section>
  

  
<section class="section">
  <div class="container is-max-desktop">

   
    <!-- Experiments -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Qualitative and Quantitative Results</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">Qualitative Results</h3>
        <div class="content has-text-justified">
          <p>
            Here are some qualitative results.
          </p>
        </div>
        <div class="content has-text-centered">
        <img src="./imgs/vis_result_main.jpg" alt="Qualitative Results" style="width:70%; max-width:800px; margin-bottom: 30px;">
        </div>
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">Quantitative Results</h3>
        <div class="content has-text-justified">
          <p>
            Here are critical experiment results in zero-shot HOI detection.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./imgs/quantitative_results.jpg" alt="Quantitative Results" style="width:80%; max-width:800px; margin-bottom: 30px;">
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Experiments -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>    @inproceedings{lei2025lordhoi,
      title     = {LoRD-HOI: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation},
      author    = {Lei, Qinqian and Wang, Bo and Robby T., Tan},
      booktitle = {In Proceedings of the IEEE/CVF international conference on computer vision},
      year      = {2025}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
